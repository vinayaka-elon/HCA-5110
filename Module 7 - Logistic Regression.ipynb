{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c774a8-ebfc-4278-9a84-23f4998e9e6a",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee42092-9893-47bd-9b05-5b4cfdf77707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression                    # Import Logistic Regression\n",
    "from sklearn.preprocessing import LabelEncoder                         # Encoding categorical data\n",
    "from sklearn.model_selection import train_test_split                   # Splitting dataset into traning and testing sets\n",
    "from sklearn.metrics import classification_report, confusion_matrix    # Evaluting the performance of the classifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# More performance metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29939d-799e-4fff-be2a-aeee598e46a3",
   "metadata": {},
   "source": [
    "### 2. Import Data\n",
    "\n",
    "```python \n",
    "df = pd.read_excel(file) # if excel file\n",
    "df = pd.read_csv(file)   # if csv file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b6662-ada3-4f37-a734-68bc95dc93e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b08a0834-2c55-41a0-b8be-e422fa7d1862",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730daee5-a416-4758-b17d-5554d462145b",
   "metadata": {},
   "source": [
    "#### 3.1 Basic Overview\n",
    "\n",
    "```python \n",
    "df.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e25e8-f9f5-43b4-bafc-8a32fe09eb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5034d268-6484-4862-969c-cf3bfcc3aa59",
   "metadata": {},
   "source": [
    "#### 3.2 Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02432a-59b2-43be-9002-7dac1fd828ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71173d23-6e37-4642-a957-5808132be5c9",
   "metadata": {},
   "source": [
    "#### 3.3 Missing values (Nulls)\n",
    "```python \n",
    "df.dropna() # Remove rows\n",
    "df.dropna(axis=1) # Remove columns\n",
    "df[col] = df[col].fillna(np.mean(df[col])) # Fill with mean\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2827a-62f8-4705-a3e5-643c74a76a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e67438-cb2d-4d66-b119-b589ee5b4735",
   "metadata": {},
   "source": [
    "#### 3.4 Outliers\n",
    "\n",
    "```python \n",
    "df.describe()   # descriptive statistics\n",
    "filtered_df = df[(df[column] > value) # Filter outliers \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc4f2f-8fd3-4ece-b30a-26679f26be70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80c435d-dca1-4f01-b2d1-35e0927e2333",
   "metadata": {},
   "source": [
    "#### 3.5 Duplicates\n",
    "\n",
    "```python\n",
    "df.drop_duplicates # Drop Duplicates\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5529100-d54f-41c2-ae97-9a4d335a6b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1425c850-2d9a-4e27-bb2a-9b1a85b4c704",
   "metadata": {},
   "source": [
    "### 4. EDA\n",
    "\n",
    "- **Drop nominal variabless:** new_df = df.drop([List of columns], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2d701-9a5c-4576-b976-fe741775ef3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1751715-597f-4974-824e-8c7e31643597",
   "metadata": {},
   "source": [
    "#### Convert Categorical data to numerical\n",
    "\n",
    "```python\n",
    "\n",
    "cat_features = df.select_dtypes(include = \"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# Categories to Numbers (random mapping) \n",
    "le = LabelEncoder()\n",
    "df[updated col] = le.fit_transform(df[col])\n",
    "mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# Categories to Numbers (manual mapping) \n",
    "order = [['S', 'M', 'L', 'XL']]\n",
    "ord_enc = OrdinalEncoder(categories=order)\n",
    "df[updated col] = ord_enc.fit_transform(df[[col]])\n",
    "mapping = {cat: i for i, cat in enumerate(order[0])}\n",
    "\n",
    "# Create new columns for each category\n",
    "new_df = pd.get_dummies(df, columns=[list of columns])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fcc828-db1f-4e94-b371-2c48d7fe523c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7add4515-ce6c-4308-a13b-af2afcfcfd06",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "\n",
    "```python\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd449204-58ce-4282-8dff-78b6ddc30d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1212b6e-eb95-4442-afd7-e22d5a2df1a8",
   "metadata": {},
   "source": [
    "- **Correlation**: which predictors are correlated with target?\n",
    "- **Multicollinearity**: which predictors are correlated among themselves?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503c4f1-e6a1-4f9c-a7ee-8f3735401143",
   "metadata": {},
   "source": [
    "### 5. Create input & output\n",
    "\n",
    "```python\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[[target]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad27ee-a61b-48ac-94df-2399b417d6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384e1a77-a1ad-4e3e-bf4b-bf40a53edde1",
   "metadata": {},
   "source": [
    "### 6. Develop the Logistic Regression Model\n",
    "\n",
    "```python\n",
    "logclf = LogisticRegression(max_iter=1000)\n",
    "logclf.fit(X_train, y_train)\n",
    "y_pred = logclf.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71d214-93b8-4076-a52f-b7d15afe3bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d6263b7-7941-4502-b64b-c4b66198a9ba",
   "metadata": {},
   "source": [
    "### 7. Evaluate the Model\n",
    "\n",
    "```python\n",
    "cm = confusion_matrix(y_test, prediction) \n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction)) \n",
    "\n",
    "# Coefficients\n",
    "coeff = logclf.coef_.flatten()\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Coefficients\": coeff\n",
    "}).sort_values(\"Coefficients\", ascending=False)\n",
    "feature_importance\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7dc25-85dd-403c-9070-c99d98a3ad3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846f74f6-83aa-41d5-b78d-dc986dab876b",
   "metadata": {},
   "source": [
    "### 8. Further Evaluation\n",
    "\n",
    "```python\n",
    "# Get predicted probabilities\n",
    "y_pred_prob = log_reg.predict(X_test)\n",
    "\n",
    "# Compute ROC AUC\n",
    "logit_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Statsmodels Logit (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Logit_ROC')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db433f94-79d5-48cc-a5b5-ee7ec05cdaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
